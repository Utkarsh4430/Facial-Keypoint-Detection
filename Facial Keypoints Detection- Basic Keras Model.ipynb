{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#checking where the files are\nimport os\nos.listdir(\"/kaggle/input/training\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing the rquired libraries\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom tqdm import tqdm\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lookid_data = pd.read_csv(\"/kaggle/input/IdLookupTable.csv\")\nlookid_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samplesubmission = pd.read_csv(\"/kaggle/input/SampleSubmission.csv\")\nsamplesubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/training/training.csv\")\ntrain.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling the nan values\ntrain.fillna(method = 'ffill',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preparing the training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.Image.values\ndel train['Image']\nY = train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\nfor i in tqdm(X):\n    q = [int(j) for j in i.split()]\n    x.append(q)\nlen(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.array(x)\nx = x.reshape(7049, 96,96,1)\nx  = x/255.0\nx.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the data into 90-10 train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\nx_train,x_test,y_train,y_test = tts(x,Y,random_state = 69,test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape,x_test.shape,y_train.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n# model.add(BatchNormalization())\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\nmodel.add(LeakyReLU(alpha = 0.1))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(30))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def root_mean_squared_error(y_true, y_pred):\n#         return K.sqrt(K.mean(K.square(y_pred - y_true)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam',loss = 'mean_squared_error', metrics = ['mae','acc'])\nmodel.fit(x_train,y_train,batch_size=256, epochs=50,validation_data=(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam',loss = 'mean_squared_error', metrics = ['mae'])\nmodel.fit(x,Y,batch_size=64, epochs=100)\nmodel.fit(x,Y,batch_size=128, epochs=50)\nmodel.fit(x,Y,batch_size=256, epochs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/test/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.Image.values\nx_t = []\nfor i in tqdm(test):\n    q = [int(j) for j in i.split()]\n    x_t.append(q)\nx_t = np.array(x_t)\nx_t = x_t.reshape(-1, 96,96,1)\nx_t = x_t/255.0\nx_t.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_t)\npred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lookid_list = list(lookid_data['FeatureName'])\nimageID = list(lookid_data['ImageId']-1)\npre_list = list(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rowid = lookid_data['RowId']\nrowid=list(rowid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature = []\nfor f in list(lookid_data['FeatureName']):\n    feature.append(lookid_list.index(f))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preded = []\nfor x,y in zip(imageID,feature):\n    preded.append(pre_list[x][y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rowid = pd.Series(rowid,name = 'RowId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loc = pd.Series(preded,name = 'Location')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([rowid,loc],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Utkarsh.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}